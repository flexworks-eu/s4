{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"&lt;osp\u26a1&gt; Object Storage Proxy","text":"<p>A fast and safe in-process gateway for AWS S3 and compatible services (IBM Cloud Object Storage, Minio, ...).</p> <p>\u23af Speed, Security, Simplicity. Pick three. \u23af</p>"},{"location":"#what-osp-does-why-it-matters","title":"What &lt;osp\u26a1&gt; Does &amp; Why It Matters","text":""},{"location":"#instant-identity-aware-access-to-any-bucket","title":"\ud83d\ude80 Instant, Identity-Aware Access to Any Bucket","text":"<p>Drop this proxy in front of S3, GCS, IBM COS, Azure Blob, MinIO, or Ceph. It accepts whatever your users already have\u2014OIDC, SAML, JWT, mTLS\u2014then transparently signs and routes the request to the right backend. No hard-coded keys, no presigned URLs, no code changes.</p>"},{"location":"#single-point-policy-enforcement","title":"\ud83d\udd12 Single-Point Policy Enforcement","text":"<p>Write authorization rules once in Python (or call OPA, Redis, SQL\u2014your choice). The proxy evaluates them in-process on every <code>DELETE</code>/<code>GET</code>/<code>HEAD</code>/<code>LIST</code>/<code>POST</code>/<code>PUT</code>/<code>...</code>, so compliance checks and tenant isolation happen at wire-speed, not in scattered app code.</p> <p>NEW! Apply fine-grained permissions on any prefix, make exceptions, etc.</p>"},{"location":"#zero-extra-hop-wire-speed-throughput","title":"\u26a1 Zero Extra Hop, Wire-Speed Throughput","text":"<p>Because auth and streaming live in the same memory space, there\u2019s no second network trip like with sidecars or external gateways. Data flows straight from bucket to client\u2014up to 40 % lower p99 latency in real-world benchmarks.</p>"},{"location":"#observability-where-it-counts","title":"\ud83d\udcca Observability Where It Counts","text":"<p>Built-in Prometheus metrics and OpenTelemetry traces wrap the exact bytes crossing the wire. You\u2019ll see authentication failures, object sizes, and transfer times without bolting Lua or WASM onto a generic proxy.</p>"},{"location":"#the-problems-osp-eliminates","title":"The Problems &lt;osp\u26a1&gt; Eliminates","text":"Pain Point How We Solve It Credentials sprawl &amp; secret leaks Front-end receives tokens; only the proxy holds bucket keys, so nothing sensitive reaches clients, browsers or notebooks. Slow, brittle presigned URL workflows Users hit one stable URL; the proxy handles signing on the fly. Duplicate auth logic in every service Central policy engine with Python hooks\u2014change rules in one place. Vendor lock-in &amp; expensive rewrites Abstracts away bucket type; switch providers or split traffic without touching client code. Complex proxies that require custom plugins Lightweight binary / <code>pip</code> package; you extend it with plain Python, not unfamiliar DSLs. <p>Bottom line: &lt;osp\u26a1&gt; turns object-storage access into a fast, secure, one-line integration\u2014so your team ships features instead of fighting buckets.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Scalable fast in-process gateway.</li> <li>Compatible with anything that supports the AWS SDK -&gt; aws cli/boto3, Polars, Spark, Datafusion, Presto, dbt, ...</li> <li>Decouples frontend from backend authentication and authorization: plug in your authentication and authorization services. </li> <li>Flexible extensible Python configuration and interface: pass in callables for credentials fetching, validation, lookup secret for access_key (with cache).</li> <li>Compatibility Gateway between systems that are limited to single hmac credentials pair, and distributed multi-vendor multi-credentials buckets backends.</li> <li>Seemlessly translate requests between path and virtual addressing style.</li> <li>Compatible with corporate firewalled and proxied networks.</li> <li>Low-code integration in typical storage browsers with python backend (see example #3).</li> <li>Support for presigned urls the same way as regular requests.</li> <li>Credentials support for classic hmac keypair and IBM api_key authentication.</li> <li>NEW! Apply fine-grained permissions on any prefix, make exceptions</li> </ul>"},{"location":"#architecture-overview","title":"Architecture Overview","text":""},{"location":"#performance","title":"Performance","text":"<p>Performance is pretty good.  Even when using the python callback functions, since they're only called once and then cached for the remainder of the requests or until ttl expiration.</p> <p>An upload to aws bucket: the osps profile is using &lt;osp\u26a1&gt; over https, myaws is direct.</p> <p></p>"},{"location":"#configuration","title":"Configuration","text":""},{"location":"#proxy","title":"Proxy","text":"<pre><code>    ProxyServerConfig(\n        cos_map=cos_map,\n        bucket_creds_fetcher=fetch_hmac_creds,\n        validator=do_validation,\n        http_port=6190,\n        https_port=8443,\n        threads=1,\n        verify=False,\n        hmac_keystore=hmac_keys,\n        skip_signature_validation=False,\n        hmac_fetcher=lookup_secret_key\n    )\n</code></pre> argument description optional default value cos_map bucket configuration, see below NA bucket_creds_fetcher python callable to retrieve credentials for a given bucket, to return either api key or hmac key pair \u2705 NA validator python callable, validates access for a given token/bucket combination \u2705 NA http_port server listener port on http \u2705 at least http_port or https_port, or both NA https_port server listener port on https \u2705 at least http_port or https_port, or both NA threads number of service threads \u2705 1 verify ignore ssl verification errors on backend storage (for dev purposes) \u2705 False hmac_keystore skip_signature_validation ignore ssl verification errors on frontend (for dev purposes) \u2705 False hmac_fetcher python callable, gets the private/secret key for a given public/access key \u00a0\u2705 NA"},{"location":"#buckets","title":"Buckets","text":"<ul> <li>endpoint host</li> <li>port</li> <li>api key (optional)</li> <li>hmac access key (optional)</li> <li>hmac secret key (optional)</li> <li>ttl (optional, default 300) -&gt; keep this reasonably short, but size to your needs</li> </ul> <pre><code>cos_map = {\n    \"proxy-bucket01\": {  # &lt;- no keys, will be fetched at first call\n        \"host\": \"s3.eu-de.cloud-object-storage.appdomain.cloud\",\n        \"port\": 443,\n        \"ttl\": 300\n    },\n    \"proxy-aws-bucket01\": {\n        \"host\": \"s3.eu-west-3.amazonaws.com\",\n        \"region\": \"eu-west-3\",\n        \"access_key\": os.getenv(\"AWS_ACCESS_KEY\"),\n        \"secret_key\": os.getenv(\"AWS_SECRET_KEY\"),\n        \"port\": 443,\n        \"ttl\": 300\n    }    \n}\n</code></pre>"},{"location":"#python-callback-functions","title":"Python callback functions","text":"argument description signature bucket_creds_fetcher python callable to retrieve credentials for a given bucket, to return either api key or hmac key pair <pre><code>def callable(token: str, bucket: str) -&gt; str </code></pre> validator python callable, validates access for a given token/bucket combination <pre><code>def callable(token: str, bucket: str) -&gt; bool </code></pre> hmac_fetcher python callable, gets the private/secret key for a given public/access key <pre><code>def callable(access_key: str) -&gt; Optional[str ] </code></pre> <pre><code>def do_hmac_creds(token: str, bucket: str) -&gt; str:\n    \"\"\" Fetch HMAC credentials (ro, rw, access_denied) for the given bucket, depending on the token \"\"\"\n    access_key = os.getenv(\"ACCESS_KEY\")\n    secret_key = os.getenv(\"SECRET_KEY\")\n    if not access_key or not secret_key:\n        raise ValueError(\"ACCESS_KEY or SECRET_KEY environment variable not set\")\n\n    print(f\"Fetching HMAC credentials for {bucket}...\")\n\n    return json.dumps({\n        \"access_key\": access_key,\n        \"secret_key\": secret_key\n    })\n\ndef lookup_secret_key(access_key: str) -&gt; str | None:\n    # get all environment variables ending in ACCESS_KEY\n    access_keys = [{key:value} for key, value in os.environ.items() if key.endswith(\"ACCESS_KEY\") and value==access_key ]\n\n    if len(access_keys) &gt; 0:\n        access_key_var = next((k for k, v in access_keys[0].items() if v == access_key), None)\n\n        secret_key_var = access_key_var.replace(\"ACCESS_KEY\", \"SECRET_KEY\")\n        return os.getenv(secret_key_var, None)\n    else:\n        print(f\"no access keys found for : {access_key}\")\n\n\ndef do_validation(token: str, bucket: str) -&gt; bool:\n    \"\"\" Authorize the request based on token for the given bucket. \n        You can plug in your own authorization service here.\n        The token is a client identifier used to fetch an authorization token and further authenticate/authorize.\n        The bucket is the bucket name.\n        The function should return True if the request is authorized, False otherwise.\n    \"\"\"\n\n    print(f\"PYTHON: Validating headers: {token} for {bucket}...\")\n    # return random.choice([True, False])\n    return True\n</code></pre>"},{"location":"#full-example","title":"Full example","text":"<p>With local configuration.</p> <p>~/.aws/config <pre><code>[profile osps]\nregion = eu-west-3\noutput = json\nservices = osp-services\ns3 =\n    addressing_style = path\n\n[services osps-services]\ns3 =\n  endpoint_url = https://localhost:8443\n</code></pre></p> <p>~/.aws/credentials <pre><code>[osps]\naws_access_key_id = MYLOCAL123  # &lt;-- this could be an internal client identifier, to fetch openid connect/oauth2 token or anything that makes sense for your business\naws_secret_access_key = my_private_secret # &lt;-- private key to sign original request\n</code></pre></p> <p>Set up a minimal server implementation: <pre><code>import json\nimport os\nimport random\nimport strtobool\nimport object_storage_proxy as osp\n\nfrom dotenv import load_dotenv\n\nfrom object_storage_proxy import start_server, ProxyServerConfig\n\n\ndef do_api_creds(token: str, bucket: str) -&gt; str:\n    \"\"\"Fetch credentials (ro, rw, access_denied) for the given bucket, depending on the token. \"\"\"\n    apikey = os.getenv(\"COS_API_KEY\")\n    if not apikey:\n        raise ValueError(\"COS_API_KEY environment variable not set\")\n\n    print(f\"Fetching credentials for {bucket}...\")\n    return apikey\n\n\ndef do_hmac_creds(token: str, bucket: str) -&gt; str:\n    \"\"\" Fetch HMAC credentials (ro, rw, access_denied) for the given bucket, depending on the token \"\"\"\n    access_key = os.getenv(\"ACCESS_KEY\")\n    secret_key = os.getenv(\"SECRET_KEY\")\n    if not access_key or not secret_key:\n        raise ValueError(\"ACCESS_KEY or SECRET_KEY environment variable not set\")\n\n    print(f\"Fetching HMAC credentials for {bucket}...\")\n\n    return json.dumps({\n        \"access_key\": access_key,\n        \"secret_key\": secret_key\n    })\n\ndef lookup_secret_key(access_key: str) -&gt; str | None:\n    # get all environment variables ending in ACCESS_KEY\n    access_keys = [{key:value} for key, value in os.environ.items() if key.endswith(\"ACCESS_KEY\") and value==access_key ]\n\n    if len(access_keys) &gt; 0:\n        access_key_var = next((k for k, v in access_keys[0].items() if v == access_key), None)\n\n        secret_key_var = access_key_var.replace(\"ACCESS_KEY\", \"SECRET_KEY\")\n        return os.getenv(secret_key_var, None)\n    else:\n        print(f\"no access keys found for : {access_key}\")\n\n\ndef do_validation(token: str, bucket: str) -&gt; bool:\n    \"\"\" Authorize the request based on token for the given bucket. \n        You can plug in your own authorization service here.\n        The token is a client identifier used to fetch an authorization token and further authenticate/authorize.\n        The bucket is the bucket name.\n        The function should return True if the request is authorized, False otherwise.\n    \"\"\"\n\n    print(f\"PYTHON: Validating headers: {token} for {bucket}...\")\n    return True\n\n\ndef main() -&gt; None:\n    load_dotenv()\n\n    counting = strtobool(os.getenv(\"OSP_ENABLE_REQUEST_COUNTING\", \"false\"))\n\n    if counting:\n        osp.enable_request_counting()\n        print(\"Request counting enabled\")\n\n    apikey = os.getenv(\"COS_API_KEY\")\n    if not apikey:\n        raise ValueError(\"COS_API_KEY environment variable not set\")\n\n    cos_map = {\n        \"proxy-bucket01\": {\n            \"host\": \"s3.eu-de.cloud-object-storage.appdomain.cloud\",\n            \"region\": \"eu-de\",\n            \"port\": 443,\n            \"ttl\": 300\n        },\n        \"proxy-aws-bucket01\": {\n            \"host\": \"s3.eu-west-3.amazonaws.com\",\n            \"region\": \"eu-west-3\",\n            \"access_key\": os.getenv(\"AWS_ACCESS_KEY\"),\n            \"secret_key\": os.getenv(\"AWS_SECRET_KEY\"),\n            \"port\": 443,\n            \"ttl\": 300\n        }\n    }\n\n    hmac_keys= [\n        {\n            \"access_key\": os.getenv(\"LOCAL2_ACCESS_KEY\"),\n            \"secret_key\": os.getenv(\"LOCAL2_SECRET_KEY\")\n        },\n\n    ]\n\n    ra = ProxyServerConfig(\n        cos_map=cos_map,\n        bucket_creds_fetcher=do_hmac_creds,\n        validator=do_validation,\n        http_port=6190,\n        https_port=8443,\n        threads=1,\n        # verify=False, &lt;-- DEV/TEST only\n        hmac_keystore=hmac_keys,\n        skip_signature_validation=False,\n        hmac_fetcher=lookup_secret_key\n    )\n\n    start_server(ra)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre></p> <p>Run with aws-cli (but could be anything compatible with the aws s3 api like polars, spark, presto, ...):</p> <pre><code>$ aws s3 ls s3://proxy-bucket01/ --recursive --summarize --human-readable --profile osp\n2025-04-17 17:45:30   33 Bytes README.md\n2025-04-17 17:48:04   33 Bytes README2.md\n\nTotal Objects: 2\n   Total Size: 66 Bytes\n$\n</code></pre> <p>See more examples here.</p>"},{"location":"#more-examples","title":"More Examples","text":""},{"location":"#upload-to-an-aws-bucket","title":"Upload to an aws bucket","text":"<p>Profile osps is using &lt;osp\u26a1&gt; over https, myaws is direct.</p> <p></p>"},{"location":"#generate-tpc-h-test-data-using-duckdb","title":"Generate TPC-H test data using duckdb","text":"<p>Generate some TPC-H testdata using  dbgen with a table on an aws bucket and another table on an ibm cos bucket. </p> <p></p> <p></p> <p>Create two dataframes from the tpc-h dataset generated earlier, for customer and orders. Get the top 10 customers. All using a single set of credentials.</p> <pre><code>import os\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, count, max as _max, desc\n\naccess_key = os.environ[\"AWS_ACCESS_KEY_ID\"]\nsecret_key = os.environ[\"AWS_ACCESS_SECRET_KEY\"]\n\nspark = SparkSession.builder \\\n    .appName(\"TPCH\") \\\n    .config(\"spark.hadoop.fs.s3a.access.key\", access_key) \\\n    .config(\"spark.hadoop.fs.s3a.secret.key\", secret_key) \\\n    .config(\"spark.hadoop.fs.s3a.endpoint\", f\"https://localhost:8443\") \\\n    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n    .getOrCreate()\n\nspark.sparkContext.setLogLevel(\"ERROR\")\n\ncustomers = spark.read.parquet(\"s3a://proxy-bucket01/tpch/sf10/customer/\")\norders    = spark.read.parquet(\"s3a://proxy-aws-bucket01/tpch/sf10/orders/\")\n\n# join, aggregate, sort, and limit\ntop10_customers = (\n    customers\n      .join(orders, customers.c_custkey == orders.o_custkey)\n      .groupBy(\n          customers.c_custkey.alias(\"custkey\"),\n          customers.c_name.alias(\"name\")\n      )\n      .agg(\n          count(orders.o_orderkey).alias(\"order_count\"),\n          _max(orders.o_orderdate).alias(\"last_order_date\")\n      )\n      .orderBy(desc(\"order_count\"))\n      .limit(10)\n)\n\ntop10_customers.show(truncate=False)\n</code></pre> <p></p>"},{"location":"#integrated-in-a-fastapi-app","title":"\ud83d\udd1c Integrated in a Fastapi app","text":"<p>Using &lt;osp\u26a1&gt; for download/upload interface within a fastapi python backend (using &lt;/&gt; htmx for our convenience)</p> <p>Then, ie. when a download link is clicked, generate a presigned link in either a dialog for the user or hidden on the page and use javascript to initiate the download.</p>"},{"location":"#presigned-url","title":"Presigned url","text":"<p>Generate a presigned url against the &lt;osp\u26a1&gt; endpoint and download a file, going through the same &lt;osp\u26a1&gt; gateway.</p> <p></p>"},{"location":"#query-from-two-different-vendors-using-presto","title":"Query from two different vendors using Presto","text":"<p>Create TPC-H customer and order tables using spark, on two different buckets, customer on aws and orders on ibm bucket.</p> <pre><code>import os\nfrom pyspark.sql import SparkSession\n\naws_access_key_id = os.environ[\"AWS_ACCESS_KEY_ID\"]\naws_secret_access_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\nregion = \"eu-west-3\"\n\nspark = (\n    SparkSession.builder.appName(\"S3AExample\")\n    .config(\"spark.hadoop.fs.s3a.access.key\", aws_access_key_id)\n    .config(\"spark.hadoop.fs.s3a.secret.key\", aws_secret_access_key)\n    .config(\"spark.hadoop.fs.s3a.endpoint\", f\"http://localhost:6190\")\n    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n    .config(\"spark.sql.catalogImplementation\", \"hive\")\n    .config(\"spark.hadoop.hive.metastore.uris\", \"thrift://localhost:9083\")\n    .getOrCreate()\n)\n\nspark.sql(\n    \"\"\"\n        CREATE EXTERNAL TABLE default.customer (\n        c_custkey     BIGINT,\n        c_name        STRING,\n        c_address     STRING,\n        c_nationkey   BIGINT,\n        c_phone       STRING,\n        c_acctbal     DOUBLE,\n        c_mktsegment  STRING,\n        c_comment     STRING\n        )\n        STORED AS PARQUET\n        LOCATION 's3a://proxy-aws-bucket01/tpch/sf10/customer'\n    \"\"\"\n)\n\nspark.sql(\n    \"\"\"\n        CREATE EXTERNAL TABLE IF NOT EXISTS default.orders (\n        o_orderkey     BIGINT,\n        o_custkey      BIGINT,\n        o_orderstatus  STRING,\n        o_totalprice   DOUBLE,\n        o_orderdate    DATE,\n        o_orderpriority STRING,\n        o_clerk        STRING,\n        o_shippriority INT,\n        o_comment      STRING\n        )\n        STORED AS PARQUET\n        LOCATION 's3a://proxy-bucket01/tpch/sf10/orders'\n    \"\"\"\n)\nspark.stop()\n</code></pre> <p>Tables <pre><code>[root@dbc8ec99fdc5 /]# presto-cli --server localhost:8080 --catalog hive --schema default\npresto:default&gt; SHOW CREATE TABLE hive.default.customer;\n                             Create Table\n-----------------------------------------------------------------------\n CREATE TABLE hive.default.customer (\n    \"c_custkey\" bigint,\n    \"c_name\" varchar,\n    \"c_address\" varchar,\n    \"c_nationkey\" bigint,\n    \"c_phone\" varchar,\n    \"c_acctbal\" double,\n    \"c_mktsegment\" varchar,\n    \"c_comment\" varchar\n )\n WITH (\n    external_location = 's3a://proxy-aws-bucket01/tpch/sf10/customer',\n    format = 'PARQUET'\n )\n(1 row)\n\nQuery 20250504_175810_00013_d86su, FINISHED, 1 node\nSplits: 1 total, 1 done (100.00%)\n[Latency: client-side: 74ms, server-side: 59ms] [0 rows, 0B] [0 rows/s, 0B/s]\n\npresto:default&gt; SHOW CREATE TABLE hive.default.orders;\n                          Create Table\n-----------------------------------------------------------------\n CREATE TABLE hive.default.orders (\n    \"o_orderkey\" bigint,\n    \"o_custkey\" bigint,\n    \"o_orderstatus\" varchar,\n    \"o_totalprice\" double,\n    \"o_orderdate\" date,\n    \"o_orderpriority\" varchar,\n    \"o_clerk\" varchar,\n    \"o_shippriority\" integer,\n    \"o_comment\" varchar\n )\n WITH (\n    external_location = 's3a://proxy-bucket01/tpch/sf10/orders',\n    format = 'PARQUET'\n )\n(1 row)\n\nQuery 20250504_175812_00014_d86su, FINISHED, 1 node\nSplits: 1 total, 1 done (100.00%)\n[Latency: client-side: 74ms, server-side: 56ms] [0 rows, 0B] [0 rows/s, 0B/s]\n\npresto:default&gt;\n</code></pre></p> <p>Query tables using presto-cli</p> <p></p>"},{"location":"#contact","title":"Contact","text":"<p>\u2709\ufe0f Get in touch</p>"},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) [2025] [Flexworks]</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, and sublicense copies of the Software, subject to the following condition:</p> <p>Commons Clause License Condition v1.0</p> <p>The Software is provided under the MIT License with the following additional restriction:</p> <p>You are not granted rights to use, sell, sublicense, or distribute the Software or derivatives for commercial purposes. \"Commercial Purposes\" means the sale, lease, license, or other distribution of the Software or derivatives for monetary or commercial gain.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"}]}